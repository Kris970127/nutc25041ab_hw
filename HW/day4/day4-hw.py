import os
import base64
import operator
import requests
import json
from typing import Annotated, List, TypedDict, Literal

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END
from playwright.sync_api import sync_playwright

# --- 1. æ ¸å¿ƒæ¨¡å‹åˆå§‹åŒ– ---
llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="YOUR_API_KEY", # è«‹æ›´æ›ç‚ºæ‚¨çš„é‡‘é‘°
    model="google/gemma-3-27b-it",
    temperature=0
)

# --- 2. å®šç¾©ç‹€æ…‹ (State) ---
class AgentState(TypedDict):
    input: str
    queries: List[str]
    knowledge_base: Annotated[list, operator.add]
    search_results: List[dict]
    is_sufficient: bool
    round: int
    final_answer: str

# --- 3. æ ¸å¿ƒå·¥å…·å‡½æ•¸ ---

def search_searxng(query: str):
    """åŸ·è¡Œæœå°‹å¼•æ“æª¢ç´¢"""
    url = "https://puli-8080.huannago.com/search"
    params = {"q": query, "format": "json", "language": "zh-TW"}
    try:
        response = requests.get(url, params=params, timeout=10)
        return response.json().get('results', [])[:5] # å¤šå–å¹¾ç­†ä¾›ç¯©é¸
    except:
        return []

def vlm_read_website(url: str, title: str):
    """ä½¿ç”¨ Playwright é€²è¡Œè¦–è¦ºåŒ–é–±è®€"""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            # å¢åŠ ç­‰å¾…æ™‚é–“ç¢ºä¿å…§å®¹åŠ è¼‰
            page.goto(url, wait_until="networkidle", timeout=45000)
            page.wait_for_timeout(3000) 
            screenshot_b64 = base64.b64encode(page.screenshot()).decode('utf-8')
            browser.close()

            msg = [
                {"type": "text", "text": f"ç¶²é æ¨™é¡Œï¼š{title}ã€‚è«‹æ‘˜è¦é€™ç¯‡å ±å°ä¸­é—œæ–¼ã€Œç™¼å”®æ—¥æœŸã€å»¶æœŸç´€éŒ„ã€å®˜æ–¹å…¬å‘Šæ™‚é–“ã€çš„å…·é«”äº‹å¯¦ã€‚"},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{screenshot_b64}"}}
            ]
            return llm.invoke([HumanMessage(content=msg)]).content
    except Exception as e:
        return f"è¦–è¦ºè®€å–å¤±æ•—: {str(e)}"

# --- 4. LangGraph ç¯€é»å¯¦ä½œ ---

def check_cache_node(state: AgentState):
    print(f"ğŸ” [Cache] æª¢æŸ¥å¿«å–ï¼š{state['input']}")
    return {"round": 0, "knowledge_base": []}

def planner_node(state: AgentState):
    current_round = state.get("round", 0)
    MAX_ROUNDS = 3 
    
    print(f"\nğŸ§  [Think] Round {current_round}")
    
    if current_round >= MAX_ROUNDS:
        return {"is_sufficient": True}

    if not state.get("knowledge_base"):
        return {"is_sufficient": False, "round": current_round + 1}
    
    context = "\n".join(state["knowledge_base"])
    # å¼·åŒ–åˆ¤æ–·é‚è¼¯ï¼Œè¦æ±‚æª¢æŸ¥æ˜¯å¦æœ‰çŸ›ç›¾æˆ–ä¸å®Œæ•´
    prompt = f"å•é¡Œï¼š{state['input']}\nç›®å‰æŸ¥åˆ°çš„è³‡è¨Šï¼š{context}\né€™äº›è³‡è¨Šæ˜¯å¦æ¶µè“‹äº†è©²å•é¡Œçš„æ‰€æœ‰æ­·å²è®Šå‹•æˆ–æ¬¡æ•¸ï¼Ÿè«‹å›ç­” Y æˆ– Nã€‚"
    res = llm.invoke(prompt)
    
    is_ok = "Y" in res.content.upper()
    print(f"{'âœ… è³‡è¨Šå·²è¶³å¤ ' if is_ok else 'âŒ è³‡è¨Šä»ä¸è¶³ï¼Œç¹¼çºŒè¿½è¹¤'}")
    return {"is_sufficient": is_ok, "round": current_round + 1}

def query_gen_node(state: AgentState):
    # é‡å°å»¶æœŸå•é¡Œï¼Œç”Ÿæˆæ›´å…·è¿½æº¯æ€§çš„é—œéµå­—
    prompt = f"é‡å°å•é¡Œ '{state['input']}'ï¼Œè«‹ç”Ÿæˆä¸€å€‹èƒ½æœåˆ°ã€æ­·å²è®Šå‹•ã€æˆ–ã€å¤šæ¬¡ç´€éŒ„ã€çš„ç¹é«”ä¸­æ–‡æœå°‹é—œéµå­—ï¼ˆä¾‹å¦‚ï¼šGTA 6 æ­·æ¬¡å»¶æœŸ æ•´ç†ï¼‰ã€‚"
    res = llm.invoke(prompt)
    query = res.content.strip().replace('"', '')
    print(f"ğŸ”‘ ç”Ÿæˆé—œéµå­—ï¼š{query}")
    return {"queries": [query]}

def search_tool_node(state: AgentState):
    query = state["queries"][-1]
    print(f"ğŸŒ è¨ªå•ï¼šåŸ·è¡Œ SearXNG ç¶²è·¯æœå°‹...")
    return {"search_results": search_searxng(query)}

def vlm_processing_node(state: AgentState):
    """å„ªåŒ–ï¼šä¸€æ¬¡è®€å–å‰ 2 ç­†çµæœï¼Œç¢ºä¿ä¸æ¼æ‰èˆŠè³‡è¨Š"""
    new_info = []
    results = state.get("search_results", [])
    
    # è®€å–å‰ 2 ç­†ä¸åŒçš„ä¾†æº
    for i in range(min(2, len(results))):
        target = results[i]
        print(f"ğŸ“¸ [VLM] å•Ÿå‹•è¦–è¦ºé–±è®€ ({i+1}/2)ï¼š{target.get('title')[:20]}...")
        summary = vlm_read_website(target['url'], target.get('title', 'ç„¡æ¨™é¡Œ'))
        new_info.append(f"ã€ä¾†æº {i+1}ã€‘: {target['url']}\nã€æ‘˜è¦ã€‘: {summary}\n")
    
    print(f"ğŸ“ å…§å®¹å·²æˆåŠŸå­˜å…¥çŸ¥è­˜åº«")
    return {"knowledge_base": new_info}

def final_answer_node(state: AgentState):
    print(f"\nğŸ [Output] æ­£åœ¨ç”Ÿæˆæœ€çµ‚æŸ¥è­‰å›ç­”...")
    context = "\n".join(state.get("knowledge_base", []))
    
    prompt = f"""
    è«‹æ ¹æ“šä»¥ä¸‹å¤šå€‹ä¾†æºçš„è³‡è¨Šï¼Œåš´è¬¹åœ°å›ç­”å•é¡Œï¼š{state['input']}
    
    è¦æ±‚ï¼š
    1. è‹¥ä¸åŒä¾†æºæåˆ°çš„æ¬¡æ•¸æˆ–æ—¥æœŸä¸åŒï¼Œè«‹å®Œæ•´åˆ—å‡ºè®Šå‹•æ­·ç¨‹ã€‚
    2. ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¿ç•™å°ˆæœ‰åè©ã€‚
    3. æ¡ç”¨ã€Œæ¢åˆ—å¼ã€èªªæ˜å„éšæ®µçš„æ—¥æœŸã€‚
    4. è‹¥æœ‰æ˜ç¢ºçš„å»¶æœŸæ¬¡æ•¸ï¼Œè«‹ç›´æ¥æŒ‡å‡ºã€‚
    
    åƒè€ƒè³‡è¨Šï¼š
    {context}
    """
    res = llm.invoke(prompt)
    return {"final_answer": res.content}

# --- 5. æ§‹å»ºåœ–è¡¨ ---
workflow = StateGraph(AgentState)
workflow.add_node("check_cache", check_cache_node)
workflow.add_node("planner", planner_node)
workflow.add_node("query_gen", query_gen_node)
workflow.add_node("search_tool", search_tool_node)
workflow.add_node("vlm_processing", vlm_processing_node)
workflow.add_node("final_answer", final_answer_node)

workflow.set_entry_point("check_cache")
workflow.add_edge("check_cache", "planner")

workflow.add_conditional_edges(
    "planner",
    lambda x: "end" if x["is_sufficient"] else "search",
    {"end": "final_answer", "search": "query_gen"}
)

workflow.add_edge("query_gen", "search_tool")
workflow.add_edge("search_tool", "vlm_processing")
workflow.add_edge("vlm_processing", "planner")
workflow.add_edge("final_answer", END)

app = workflow.compile()

# --- 6. äº’å‹•åŸ·è¡Œ ---
print(app.get_graph().draw_ascii())
if __name__ == "__main__":
    user_q = input("ğŸ” è«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è­‰çš„å•é¡Œ: ")
    if user_q.strip():
        final_state = app.invoke({
            "input": user_q, 
            "knowledge_base": [], 
            "queries": [], 
            "search_results": [],
            "round": 0
        })
        print("\nğŸ¯ ã€æœ€çµ‚æŸ¥è­‰çµæœã€‘")
        print(final_state.get("final_answer", "æœªèƒ½ç”Ÿæˆç­”æ¡ˆ"))